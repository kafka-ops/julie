---
version: '2.3'
services:

  phpldapadmin-service:
    image: osixia/phpldapadmin:0.7.2
    container_name: ldapadmin-service
    environment:
      - PHPLDAPADMIN_LDAP_HOSTS=openldap
    ports:
      - "6444:443"
    depends_on:
      - openldap

  openldap:
    image: rroemhild/test-openldap
    hostname: openldap
    container_name: openldap
    ports:
      - "10389:10389"
    privileged: true

  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-server:5.5.1
    hostname: broker
    container_name: broker
    depends_on:
      - 'zookeeper'
      - 'openldap'
    ports:
      - "8090:8090"
      - "9092:9092"
      - "9093:9093"
      - "9094:9094"
    volumes:
      - ./conf:/tmp/conf
      - ./client-configs:/etc/client-configs
    environment:
      KAFKA_SUPER_USERS: User:admin;User:mds;User:professor
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://localhost:9093,EXTERNAL://broker:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT,OUTSIDE:SASL_PLAINTEXT
      KAFKA_CONFLUENT_METADATA_SECURITY_PROTOCOL: SASL_PLAINTEXT
       # Configure interbroker listener
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_LISTENER_NAME_INTERNAL_SASL_ENABLED_MECHANISMS: PLAIN
      # note we're only specifying two users, one for broker-to-broker communication (admin) and one for MDS to talk to broker (mds)
      KAFKA_LISTENER_NAME_INTERNAL_PLAIN_SASL_JAAS_CONFIG: |
                                                            \
                                                            org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                            username="admin" \
                                                            password="admin-secret" \
                                                            user_admin="admin-secret" \
                                                            user_mds="mds-secret";
      # Configure external listener
      KAFKA_LISTENER_NAME_EXTERNAL_SASL_ENABLED_MECHANISMS: OAUTHBEARER
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerValidatorCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerServerLoginCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: |
                                                                 \
                                                                 org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                                 publicKeyPath="/tmp/conf/public.pem";
      # Configure external listener
      KAFKA_LISTENER_NAME_OUTSIDE_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_LISTENER_NAME_OUTSIDE_PLAIN_SASL_SERVER_CALLBACK_HANDLER_CLASS: io.confluent.security.auth.provider.ldap.LdapAuthenticateCallbackHandler
      KAFKA_LISTENER_NAME_OUTSIDE_PLAIN_SASL_JAAS_CONFIG: |
                                                      \
                                                      org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                      username="admin" \
                                                      password="admin-secret";

      # CONFIGURE AUTHORIZER
      # Setup kafka to use RBAC authorizer
      KAFKA_AUTHORIZER_CLASS_NAME: io.confluent.kafka.security.authorizer.ConfluentServerAuthorizer

      # ======================== CONFIGURE MDS ====================================
      # Configure how MDS talks to broker
      KAFKA_CONFLUENT_METADATA_BOOTSTRAP_SERVERS: INTERNAL://localhost:9093
      KAFKA_CONFLUENT_METADATA_SASL_MECHANISM: PLAIN
      KAFKA_CONFLUENT_METADATA_SASL_JAAS_CONFIG: |
                                                  \
                                                  org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                  username="mds" \
                                                  password="mds-secret";
      # Configure how MDS stores its data in a topic
      # supposedly more stuff can be overridden with the same prefix
      KAFKA_CONFLUENT_METADATA_TOPIC_REPLICATION_FACTOR: 1

      # Configure MDS listener and http server
      KAFKA_CONFLUENT_METADATA_SERVER_AUTHENTICATION_METHOD: BEARER
      KAFKA_CONFLUENT_METADATA_SERVER_AUTHENTICATION_ROLES: '**'
      KAFKA_CONFLUENT_METADATA_SERVER_LISTENERS: http://0.0.0.0:8090
      KAFKA_CONFLUENT_METADATA_SERVER_ADVERTISED_LISTENERS: http://broker:8090
      KAFKA_CONFLUENT_METADATA_SERVER_OPENAPI_ENABLE: 'true'

      # Configure RBAC token server (authentication)
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_AUTH_ENABLE: 'true'
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_MAX_LIFETIME_MS: 3600000
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_SIGNATURE_ALGORITHM: RS256
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_KEY_PATH: /tmp/conf/keypair.pem
      KAFKA_CONFLUENT_METADATA_SERVER_PUBLIC_KEY_PATH: /tmp/conf/public.pem

      # Configure RBAC authorizer
      # KAFKA_CONFLUENT_AUTHORIZER_SCOPE: myCluster
      KAFKA_CONFLUENT_AUTHORIZER_ACCESS_RULE_PROVIDERS: CONFLUENT,ZK_ACL
      # KAFKA_CONFLUENT_AUTHORIZER_METADATA_PROVIDER: RBAC
      KAFKA_CONFLUENT_AUTHORIZER_GROUP_PROVIDER: RBAC
      # KAFKA_CONFLUENT_METADATA_SERVER_SCOPE: ''

      # Configure MDS to talk to AD/LDAP
      KAFKA_LDAP_JAVA_NAMING_FACTORY_INITIAL: com.sun.jndi.ldap.LdapCtxFactory
      KAFKA_LDAP_COM_SUN_JNDI_LDAP_READ_TIMEOUT: 3000
      KAFKA_LDAP_JAVA_NAMING_PROVIDER_URL: ldap://openldap:10389
      # how to authenticate to LDAP
      KAFKA_LDAP_JAVA_NAMING_SECURITY_PRINCIPAL: cn=admin,dc=planetexpress,dc=com
      KAFKA_LDAP_JAVA_NAMING_SECURITY_CREDENTIALS: GoodNewsEveryone
      KAFKA_LDAP_JAVA_NAMING_SECURITY_AUTHENTICATION: simple
      # how to locate users and groups
      KAFKA_LDAP_USER_SEARCH_BASE: ou=people,dc=planetexpress,dc=com
      KAFKA_LDAP_GROUP_SEARCH_BASE: ou=people,dc=planetexpress,dc=com
      KAFKA_LDAP_USER_NAME_ATTRIBUTE: uid
      KAFKA_LDAP_USER_OBJECT_CLASS: inetOrgPerson
      KAFKA_LDAP_USER_MEMBEROF_ATTRIBUTE: ou
      KAFKA_LDAP_GROUP_NAME_ATTRIBUTE: cn
      KAFKA_LDAP_GROUP_OBJECT_CLASS: group

      # ======================= CONFIGURE METRICS REPORTER =========================
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1

      # point at our 'INTERNAL' listener
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:9093
      # CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONFLUENT_METRICS_REPORTER_SASL_MECHANISM: PLAIN
      CONFLUENT_METRICS_REPORTER_SASL_JAAS_CONFIG: |
                                                    \
                                                    org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                    username="admin" \
                                                    password="admin-secret";
      # ======================= OTHER BROKER STUFF =================================
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # CONFLUENT_METRICS_ENABLE: 'true'
      # CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

  schema-registry:
    image: confluentinc/cp-schema-registry:5.5.1
    hostname: schema-registry
    container_name: schema-registry
    ports:
      - "8081:8081"
    volumes:
      - ./conf:/tmp/conf
    environment:
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/schema-registry/*:/usr/share/java/schema-registry/*'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      # This is only needed if you don't have a license and would like to test as part of a trial period
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

      # configure how to connect to kafka for SR to store its internal info
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:9092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_PLAINTEXT
      SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: OAUTHBEARER
      SCHEMA_REGISTRY_KAFKASTORE_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
      SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: |
                                                    \
                                                    org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                    username="leela" \
                                                    password="leela" \
                                                    metadataServerUrls="http://broker:8090";
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_DEBUG: 'true'

      # ======================= RBAC =================================
      SCHEMA_REGISTRY_SCHEMA_REGISTRY_RESOURCE_EXTENSION_CLASS: io.confluent.kafka.schemaregistry.security.SchemaRegistrySecurityResourceExtension
      SCHEMA_REGISTRY_CONFLUENT_SCHEMA_REGISTRY_AUTHORIZER_CLASS: io.confluent.kafka.schemaregistry.security.authorizer.rbac.RbacAuthorizer
      SCHEMA_REGISTRY_REST_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
      # how to connect to MDS
      SCHEMA_REGISTRY_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://broker:8090
      SCHEMA_REGISTRY_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: BASIC
      SCHEMA_REGISTRY_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: leela:leela
      # public key to verify tokens during authentication
      SCHEMA_REGISTRY_PUBLIC_KEY_PATH: /tmp/conf/public.pem

  connect:
    image: confluentinc/cp-server-connect:5.5.1
    hostname: connect
    container_name: connect
    depends_on:
      - 'broker'
    ports:
      - "8083:8083"
    volumes:
      - ./conf:/tmp/conf
    # - ./connect-source:/tmp/connect-source
    #  - ./connect-sink:/tmp/connect-sink
    healthcheck:
        test: nc -z localhost 8083
        interval: 3s
        retries: 15
        start_period: 30s
    environment:
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/connect/*:/usr/share/java/kafka/*'
      # we can run without zookeeper connect in local environment
      # CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'

      # general settings
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-cluster
      # configs storage topic
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      # offsets storage topic and settings
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      # status storage topic
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

      # Default to Json converters:
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter

      # Connect to broker
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      CONNECT_SASL_JAAS_CONFIG: |
                                \
                                org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                username="fry" \
                                password="fry" \
                                metadataServerUrls="http://broker:8090";
      # Allow overriding configs on the connector level
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: 'All'
      # Default producer configs
      CONNECT_PRODUCER_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_PRODUCER_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_PRODUCER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      # Default consumer configs
      CONNECT_CONSUMER_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_CONSUMER_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_CONSUMER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      # Default admin config
      CONNECT_ADMIN_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_ADMIN_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_ADMIN_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      # Load confluent plugins
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      # ============================== RBAC ========================================
      CONNECT_REST_EXTENSION_CLASSES: 'io.confluent.connect.security.ConnectSecurityExtension,io.confluent.connect.secretregistry.ConnectSecretRegistryExtension'
      CONNECT_REST_SERVLET_INITIALIZOR_CLASSES: 'io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler'
      CONNECT_PUBLIC_KEY_PATH: '/tmp/conf/public.pem'
      CONNECT_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: 'http://broker:8090'
      CONNECT_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: 'fry:fry'
      CONNECT_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: 'BASIC'
      # ========================= SECRET REGISTRY ==================================
      CONNECT_CONFIG_PROVIDERS: 'secret'
      CONNECT_CONFIG_PROVIDERS_SECRET_CLASS: 'io.confluent.connect.secretregistry.rbac.config.provider.InternalSecretConfigProvider'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_MASTER_ENCRYPTION_KEY: 'password1234'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_TOPIC: '_confluent-secrets'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_JAAS_CONFIG: |
                                                                          \
                                                                          org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                                          username="fry" \
                                                                          password="fry" \
                                                                          metadataServerUrls="http://broker:8090";

  control-center:
    image: confluentinc/cp-enterprise-control-center:5.5.1
    hostname: control-center
    container_name: control-center
    depends_on:
      - 'zookeeper'
      - 'broker'
      - 'connect'
    ports:
      - "9021:9021"
    volumes:
      - ./conf:/tmp/conf
    environment:
      # CUB CLASSPATH
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-control-center/*:/usr/share/java/rest-utils/*:/usr/share/java/confluent-common/*'
      # CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-control-center/*'
      # general settings
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

      # ========================= other services ==============================
      # connect
      CONTROL_CENTER_CONNECT_CONNECT1_CLUSTER: http://connect:8083
      # schema-registry
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

      # ========================= RBAC =================================
      CONTROL_CENTER_REST_AUTHENTICATION_METHOD: BEARER
      PUBLIC_KEY_PATH: /tmp/conf/public.pem

      CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: hermes:hermes
      CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://broker:8090

      CONTROL_CENTER_STREAMS_SECURITY_PROTOCOL: SASL_PLAINTEXT
      # The following configs are not required by C3 itself, but are required by cub to be able to connect to kafka to check if its ready
      # Seems like C3 would generate these configs when started, but cub runs before C3 starts, so it doesn't have access to these configs
      CONTROL_CENTER_STREAMS_SASL_MECHANISM: OAUTHBEARER
      CONTROL_CENTER_STREAMS_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
      CONTROL_CENTER_STREAMS_SASL_JAAS_CONFIG: |
                                                \
                                                org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                username="hermes" \
                                                password="hermes" \
                                                metadataServerUrls="http://broker:8090";
